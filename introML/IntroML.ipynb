{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctico de Introducción a Machine Learning\n",
    "\n",
    "En este práctico implementaremos modelos sencillos de clasificiación para intentar predecir el ausentismo en los turnos. Vamos a experimentar con modelos lineales y con árboles de decisión. Nuestro objetivo no será construir el mejor modelo, sino ganar un poco más de intuición sobre nuestro conjunto de datos, y tomar algunas decisiones sobre las que profundizaremos en el próximo práctico.\n",
    "\n",
    "### Preprocesamiento\n",
    "\n",
    "Antes de aplicar los modelos, haremos un filtrado de los datos. Se sugiere seguir los siguientes pasos, pero pueden experimentar ustedes también otras alternativas\n",
    "\n",
    "- Seleccionar sólo los registros cuyo estado de turno sea \"Ausente\" o \"Atendido\". Esta variable será nuestra variable objetivo, sobre la cual buscaremos hacer predicciones.\n",
    "\n",
    "- Remover los siguientes registros:\n",
    "\n",
    "    - Turnos con pacientes menores de edad. \n",
    "\n",
    "    - Turnos en días domingo.\n",
    "\n",
    "    - Pacientes sin datos en columna \"Sexo\"\n",
    "\n",
    "    - Consultas de guardia\n",
    "\n",
    "    - Consultas de pediatría\n",
    "\n",
    "    - Registros cuyo centro de atención sea \"1\" o \"2\"\n",
    "    \n",
    "- Crear los siguientes features:\n",
    "\n",
    "    - **Anticipación de reserva**. Diferencia entre la fecha del turno y la fecha de otorgado. En caso de que la fecha de otorgado sea mayor a la del turno, colocar el valor 0.\n",
    "    \n",
    "    - **Día de la semana**. \n",
    "    \n",
    "    - **Consulta médica**. Variable binaria construida a partir del campo \"Prestación asignada\", que vale 1 si la prestación es una consulta médica, o 0 si es de otro tipo.\n",
    "    \n",
    "    - **Consumidor final**. Variable binaria construida a partir del campo \"Prestador\", que vale 1 si se trata de un consumidor final, o 0 si cuenta con obra social o prepaga.\n",
    "    \n",
    "Una vez realizados los pasos previos (o los que ustedes consideren pertinentes) debemos decidir qué hacer con los valores nulos que hayan quedado. Dado que los modelos no pueden recibir valores nulos, es necesario tomar una decisión (descartarlos, reemplazarlos por algún valor representativo, descartar alguna columna, etc.). Utilicen el criterio que consideren adecuado en este caso.\n",
    "\n",
    "Una vez que el dataset resultante no tenga valores nulos, es necesario transformar las variables categóricas en variables numéricas (es decir, realizar un encoding de los datos). Las recomendaciones en este caso son:\n",
    "\n",
    "- Realizar one-hot encoding para los campos\n",
    "\n",
    "    - Día de la semana \n",
    "    - Tipo de turno\n",
    "    - Centro de atención\n",
    "    \n",
    "    \n",
    "- Transformar en variables binarias los campos\n",
    "\n",
    "    - Estado del turno (\"Ausente\" == 1, \"Atendido\" = 0)\n",
    "    - Sexo\n",
    "    - Es sobre turno\n",
    "    - Consulta médica\n",
    "    - Consumidor final\n",
    "    \n",
    "Pueden ver más sobre encoding [acá](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd).\n",
    "\n",
    "### Elección de los modelos\n",
    "\n",
    "Con los pasos anteriores, nuestro dataset debería ser una tabla con valores numéricos y sin valores nulos. Ahora, deberán separar el conjunto de datos en conjunto de entrenamiento (train) y conjunto de prueba (test). Por ahora, no utilizaremos conjunto de validación. Se recomienda utilizar el método `train_test_split` de `scikitlearn`, con un 80% para train y 20% para test.\n",
    "\n",
    "Una vez divididos los datos, construimos los modelos predictivos. Deberán elegir (al menos) dos modelos [lineales](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) y dos modelos basados en [árboles de decisión](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble). Entrenen cada modelo utilizando el conjunto de entrenamiento y los parámetros por defecto y evaluen la predicción utilizando las cuatro métricas descriptas más adelante. ¿Qué diferencias hay entre los distintos modelos? ¿Qué tan buenas son las predicciones?\n",
    "\n",
    "Jueguen un poco variando algunos parámetros (no es necesario hacer una búsqueda sistemática). ¿Qué parámetros influyen más en el desempeño de los clasificadores? ¿Por qué les parece que algunos parámetros influyen más que otros?\n",
    "\n",
    "Repitan el proceso pero normalizando los datos de entrada (pueden usar, por ejemplo `MinMaxScaler` o `StandardScaler`). ¿Hay alguna diferencia en el resultado de los modelos? ¿A qué se debe?\n",
    "\n",
    "Finalmente, intenten mejorar las predicciones agregando o quitando features, o variando el tipo de encoding. En base a los resultados que vayan obteniendo, determinen los features que ustedes consideren que son más informativos (aquellos que ayudan a mejorar la predicción) y aquellos que sean redundantes, o que empeoren el resultado.\n",
    "\n",
    "### Elección de métricas\n",
    "\n",
    "Un aspecto fundamental del aprendizaje automático es la elección de métricas para evaluar los modelos predictivos. En este práctico vamos a explorar las siguientes cuatro métricas:\n",
    "\n",
    "- Accuracy\n",
    "- F1\n",
    "- AUC ROC\n",
    "- AUC Precision-Recall\n",
    "\n",
    "Para cada uno de los modelos que utilicen, calculen las cuatro métricas. ¿Qué información brinda cada una? ¿Hay algún inconveniente en utilizar alguna de ellas? ¿Cuáles les parece que pueden ser de utilidad para nuestra problemática? Pueden encontrar información sobre las últimas dos [acá](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación en conjunto de entrenamiento y conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.Predict(X_test)\n",
    "\n",
    "print('Accuracy score = ', accuracy_score(y_test, y_pred))\n",
    "print('F1 score = ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árboles de desición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.Predict(X_test)\n",
    "\n",
    "print('Accuracy score = ', accuracy_score(y_test, y_pred))\n",
    "print('F1 score = ', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ausentismo] *",
   "language": "python",
   "name": "conda-env-ausentismo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
